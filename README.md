
# Level2-ObjectDetection Competetion
ğŸŒŸ**CV-08**ì¡°ğŸŒŸ **MakeZenerator íŒ€**
ê¹€íƒœì–‘, ê¹€í˜œì§€, ì‹ í˜¸ì¤€, ì„±ì£¼í¬, ì„ì„œí˜„, ì •ì†Œìœ¤

## Project Structure

```
${PROJECT}
 â”ƒ  
 â”£ Data_EDA
 â”ƒ â”— visualizer.ipynb  
 â”ƒ â”— visualizer_save.py 
 â”ƒ
 â”£ dataset.py
 â”£ east_dataset.py
 â”£ file_rename.py
 â”£ json_convert.py
 â”£ detect.py
 â”£ loss.py
 â”£ model.py
 â”£ deteval.py
 â”£ train.py
 â”£ inference.py
 â”ƒ
 â”£ .github
 â”£ .gitignore  
 â”£ .gitmessage.txt  
 â”£ .pre-commit-config.yaml  
 â”— README.md  
```

- Data_EDA : This folder contains..
- FOR dataset : dataset.py, east_dataset.py, file_rename.py, json_convert.py, detect.py
- FOR Models : loss.py, model.py, deteval.py
- FOR Tools : train.py, inference.py
- README.md
- requirements.txt : contains the necessary packages to be installed

## Code Structure Description 

**Data EDA**

 - Use MaskSplitByProfileDataset
 - Downsampling
 - Stratified Kfold

**Model**
 - Ensemble `Soft Voting`
 - Learn additional Fine Tuning based on the public pretrained model
	 `EfficientNet` + `ConvNext` + `ConvNext(Stratified Kfold)`


## Getting Started

### Setting up Vitual Enviornment

1. Initialize and update the server
	```
    su -
    source .bashrc
    ```

2. Create and Activate a virtual environment in the project directory

	```
    conda create -n env python=3.8
    conda activate env
	```

4. To deactivate and exit the virtual environment, simply run:

	```
	deactivate
	```

### ??? Install Requirements

To Insall the necessary packages liksted in `requirements.txt`, run the following command while your virtual environment is activated:
```
pip install -r requirements.txt
```

### Usage
[Description of all arguments]()

#### Training

To train the model with your custom dataset, set the appropriate directories for the training images and model saving, then run the training script.
- **single model**

```
python train.py --data_dir /path/to/images --model_dir /path/to/model --model MODEL_NAME
```

- **single multiple model**

```
python train_single_multiple.py --data_dir /path/to/images --model_dir /path/to/model --model MODEL_NAME
```


#### Inference

For generating predictions with a trained model, provide directories for evaluation data, the trained model, and output, then run the inference script.
- **single model**
```
python inference.py --data_dir /path/to/images --model_dir /path/to/model --output_dir /path/to/model --model MODEL_NAME
```
- **single multiple model**
```
python inference.py --data_dir /path/to/images --model_dir /path/to/model --output_dir /path/to/model --model_mode single_multiple --model MODEL_NAME
```

#### Ensemble
- **ensemble (hard voting)**
```
python hard_voting.py --file_dir ./csv --csv1 file1.csv --csv2 file2.csv --csv3 file3.csv
```

- **ensemble (soft voting)**
```
python soft_voting.py --models MODEL_NAME1 MODEL_NAME2 MODEL_NAME3 --model_dir ./checkpoint --model_files file1.pth file2.pth file3.pth --data_dir ./data/eval
```


### [Arguments](./docs/arguments.md)

## Model
- [ConvNext Tiny](./docs/ConvNext.md)
- [EfficientNet v2 small](./docs/EfficientNet.md)
- [ViT16](./docs/ViT16.md)

## Dataloader
- [oversampling with data augmentation](./docs/data_sampling.md)
